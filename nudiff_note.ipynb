{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e575a01-21bb-46f2-99d8-34d6b5ffa328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, shutil, random, pickle, time\n",
    "import numpy as np\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable \n",
    "import torch.cuda\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import reduce\n",
    "from skimage.morphology import binary_erosion, binary_dilation, disk\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from nudiff.image_syn.utils.datasets import get_hv\n",
    "from nudiff.image_syn.utils.post_proc import get_instance_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1702ce69-bba3-42a1-99ad-72b912376e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, transform):\n",
    "        self.imgs = sorted(glob.glob(f'{img_dir}/*.png'))\n",
    "        self.labels = sorted(glob.glob(f'{label_dir}/*.tif'))\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.imgs[idx]\n",
    "        img = Image.open(self.imgs[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        label = io.imread(self.labels[idx])\n",
    "        n_unique = len(np.unique(label))\n",
    "        return img, label, n_unique, img_path\n",
    "\n",
    "def extract_patches(image, shape, step_size):\n",
    "    H, W = image.shape[:2]\n",
    "    h, w = shape\n",
    "    assert H >= h, 'image height < patch height!'\n",
    "    assert W >= w, 'image width < patch width!'\n",
    "    hstep, wstep = (H - h) // step_size + 1, (W - w) // step_size + 1\n",
    "    hflag, wflag = ((H - h) % step_size != 0), ((W - w) % step_size != 0)\n",
    "    # print(H, W, h, w, hstep, wstep, hflag, wflag)\n",
    "    patches = []\n",
    "    for i in range(hstep):\n",
    "        for j in range(wstep):\n",
    "            ytl, xtl = i * step_size, j * step_size\n",
    "            ybr, xbr = ytl + h, xtl + w\n",
    "            patch = image[ytl:ybr, xtl:xbr]\n",
    "            patches.append(patch)\n",
    "        if wflag:\n",
    "            ytl, xtl = i * step_size, W - w\n",
    "            ybr, xbr = ytl + h, W\n",
    "            patch = image[ytl:ybr, xtl:xbr]\n",
    "            patches.append(patch)\n",
    "    if hflag:\n",
    "        for j in range(wstep):\n",
    "            ytl, xtl = H - h, j * step_size\n",
    "            ybr, xbr = H, xtl + w\n",
    "            patch = image[ytl:ybr, xtl:xbr]\n",
    "            patches.append(patch)\n",
    "    if hflag & wflag:\n",
    "        patch = image[(H-h):H, (W-w):W]\n",
    "        patches.append(patch)\n",
    "    return patches\n",
    "\n",
    "def relabel_instances(inst_map):\n",
    "    new_map = np.zeros_like(inst_map)\n",
    "    indices = np.unique(inst_map)\n",
    "    n = 0\n",
    "    for ind in indices:\n",
    "        ind_map = inst_map == ind\n",
    "        new_map[np.where(ind_map == True)] = n\n",
    "        n += 1\n",
    "    return new_map\n",
    "\n",
    "def filter_patch(mask, prop=0.1, num=10):\n",
    "    # print((mask != 0).sum()/mask.size)\n",
    "    if (mask != 0).sum() / mask.size < prop or len(np.unique(mask)) - 1 < num:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def semantic_map(inst_map):\n",
    "    sem = 255 * (inst_map > 0)\n",
    "    return sem.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94af44cd-456a-4de8-82f5-f632e6f9272a",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "We take MoNuSeg dataset as an example to show the pipeline:\n",
    "\n",
    "0. Data preprocess: Extract 256x256 patches and create 10%, 20%, 50%, 100% subsets.\n",
    "1. Train DDPMs: Train unconditional DDPM (step1) and conditional DDPM (step2) for each proportion. The two DDPMs can be trained at the same time.\n",
    "2. Generate synthetic samples: \n",
    "    * After training DDPMs, mannually select model checkpoints according to the visualization results (every 10000 steps). Typically, select step1 checkpoint >= 100000 steps, and step2 checkpoint >= 200000 steps.\n",
    "    * Sample N synthetic nuclei structures with the selected step1 checkpoint. Also get instance maps from nuclei structures by watershed algorithm.\n",
    "    * Sample N synthetic nuclei images conditioned on the N synthetic nuclei structures with the selected step2 checkpoint.\n",
    "3. Train hover-net and test: It is recommended to go through this process with 10%/20%/50%/100% labeled to get the baseline segmentation performance, then 10%/20%/50%/100% augmented to compare with the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0d195a-1d79-4d76-b8da-df387d4353a6",
   "metadata": {},
   "source": [
    "# 0. Data preprocess\n",
    "Extract 256x256 patches, cluster, and select patches close to cluster centers such that 10%/20%/50%/100% subset has about 10%/20%/50%/100% nuclei instances of the original training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d538d476-cf47-4c00-8169-ef309c9df0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use 256x256, 128 stride data\n",
    "data_root = '' # path to monuseg training set\n",
    "images = sorted(glob.glob(f'{data_root}/images/*.png'))\n",
    "labels = sorted(glob.glob(f'{data_root}/labels/*.mat'))\n",
    "print(len(images), len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eff882-fb3b-4ecf-94a3-0fca1b798bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = sio.loadmat(labels[0])\n",
    "plt.imshow(label['inst_map'])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46d4dab-db67-46c8-a889-8a6113cbbde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract 256 patches from original images: no patch filtering\n",
    "save_root = 'monuseg' # root directory for saving patches\n",
    "split = 'train' # train or test\n",
    "patch_size = (256, 256)\n",
    "step_size = 128\n",
    "save_img = f'{save_root}/allpatch{patch_size[0]}x{patch_size[1]}_{step_size}/{split}/images'\n",
    "save_inst = f'{save_root}/allpatch{patch_size[0]}x{patch_size[1]}_{step_size}/{split}/instance_labels'\n",
    "save_sem = f'{save_root}/allpatch{patch_size[0]}x{patch_size[1]}_{step_size}/{split}/semantic_labels'\n",
    "os.makedirs(save_img, exist_ok=True)\n",
    "os.makedirs(save_inst, exist_ok=True)\n",
    "os.makedirs(save_sem, exist_ok=True)\n",
    "for n, (f1, f2) in enumerate(zip(images, labels)):\n",
    "    name = f1.split('/')[-1].split('.')[0]\n",
    "    image = io.imread(f1)\n",
    "    label = sio.loadmat(f2)\n",
    "    patches_ = extract_patches(image, patch_size, step_size)\n",
    "    inst_maps_ = extract_patches(label['inst_map'], patch_size, step_size)\n",
    "    # select patches\n",
    "    # sel_ids = [i for i in range(len(patches_)) if filter_patch(inst_maps_[i]) is True]\n",
    "    sel_ids = list(range(len(patches_)))\n",
    "    patches = [patches_[i] for i in sel_ids]\n",
    "    inst_maps = [inst_maps_[i] for i in sel_ids]\n",
    "    # inst_maps = [relabel_instances(x).astype('int16') for x in inst_maps]\n",
    "    sem_maps = [semantic_map(inst_map) for inst_map in inst_maps]\n",
    "    print(f'Patches: {len(sel_ids)}/{len(inst_maps_)}')\n",
    "    for k, patch in enumerate(patches):\n",
    "        io.imsave(f'{save_img}/{name}_{k}.png', patch)\n",
    "    for k, patch in enumerate(inst_maps):\n",
    "        io.imsave(f'{save_inst}/{name}_{k}.tif', patch)\n",
    "    for k, patch in enumerate(sem_maps):\n",
    "        io.imsave(f'{save_sem}/{name}_{k}.png', patch)\n",
    "    print(n, '/', len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06377e48-35e6-43b7-8728-249fe537306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model\n",
    "device = 'cuda:0' # set device\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "modules = list(resnet.children())[:-1]     \n",
    "model = nn.Sequential(*modules)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b0e010-3489-4393-8ef4-d3bd861f7804",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dataset\n",
    "split = 'train' # subsets are constructed with training patches\n",
    "resnet_transform = transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])\n",
    "])\n",
    "img_dir = f'{save_root}/allpatch{patch_size[0]}x{patch_size[1]}_{step_size}/{split}/images'\n",
    "label_dir = f'{save_root}/allpatch{patch_size[0]}x{patch_size[1]}_{step_size}/{split}/instance_labels'\n",
    "dataset = ClusterDataset(img_dir, label_dir, transform=resnet_transform)\n",
    "loader = DataLoader(dataset, batch_size=49, shuffle=False)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460d4b8f-d9d0-42b2-a9f7-595d35efd6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get features\n",
    "features, labels, n_uniques, img_paths = [], [], [], []\n",
    "for i, (batch, label, n_unique, path) in enumerate(tqdm(loader)):\n",
    "    batch = batch.to(device)\n",
    "    feature = model(batch)\n",
    "    features.append(feature.detach().cpu().numpy().squeeze())\n",
    "    labels.append(label.detach().numpy())\n",
    "    n_uniques.extend(n_unique.tolist())\n",
    "    img_paths.extend(list(path))\n",
    "features = np.concatenate(features, axis=0)\n",
    "labels = np.concatenate(labels, axis=0)\n",
    "n_uniques = np.array(n_uniques)\n",
    "img_paths = np.array(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac6045e-24bb-42db-b033-d0bac43e680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cluster\n",
    "K = 6\n",
    "kmeans = KMeans(init=\"random\", n_clusters=K, random_state=42)\n",
    "t0 = time.time()\n",
    "kmeans.fit(features)\n",
    "print(f'{time.time() - t0:.2f}s')\n",
    "p_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad75146b-2552-45fd-a28f-441d6ba87ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select patches close to class centers\n",
    "chunks = np.split(np.arange(1470), 30)\n",
    "prop = 1 # adjust this value such that instance percent is close to 0.1/0.2/0.5/1.0\n",
    "props = [prop] * K\n",
    "selected_ids = dict.fromkeys(list(range(K)))\n",
    "all_ids = dict.fromkeys(list(range(K)))\n",
    "inst_percents, inst_numbers, total_inst_number = [], [], 0\n",
    "for k in tqdm(range(K)):\n",
    "    # get close ids\n",
    "    distances = pairwise_distances(kmeans.cluster_centers_[k][None,:], features[p_labels == k]).squeeze()\n",
    "    cluster_ids = np.where(p_labels == k)[0]\n",
    "    n_close = int(len(cluster_ids) * props[k])\n",
    "    close_ids = cluster_ids[np.argsort(distances)[:n_close]]\n",
    "    # calculate instance proportion\n",
    "    close_unions, cluster_unions = [], []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_ids = [x for x in cluster_ids if x in chunk]\n",
    "        if len(chunk_ids) > 0:\n",
    "            cluster_union = np.unique(labels[chunk_ids])\n",
    "            cluster_unions.append(len(cluster_union))\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_ids = [x for x in close_ids if x in chunk]\n",
    "        if len(chunk_ids) > 0:\n",
    "            close_union = np.unique(labels[chunk_ids])\n",
    "            close_unions.append(len(close_union))\n",
    "    inst_percents.append(sum(close_unions) / sum(cluster_unions))\n",
    "    inst_numbers.append(sum(close_unions))\n",
    "    total_inst_number += sum(cluster_unions)\n",
    "    selected_ids[k] = close_ids\n",
    "    all_ids[k] = cluster_ids\n",
    "global_percent = sum(inst_numbers) / total_inst_number\n",
    "print(f'Global instance percent: {global_percent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec7e738-5795-4389-92a7-3f0a93246ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save patches for each proportion\n",
    "save_dir = f'{save_root}/allpatch{patch_size[0]}x{patch_size[1]}_{step_size}/train_6class_prop{global_percent:.2f}'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "os.makedirs(f'{save_dir}/images', exist_ok=True)\n",
    "os.makedirs(f'{save_dir}/instance_labels', exist_ok=True)\n",
    "os.makedirs(f'{save_dir}/semantic_labels', exist_ok=True)\n",
    "for k in range(K):\n",
    "    for path in tqdm(img_paths[selected_ids[k]]):\n",
    "        name = path.split('/')[-1].split('.')[0]\n",
    "        shutil.copy(path, f'{save_dir}/images/{name}.png')\n",
    "        shutil.copy(f'{save_root}/allpatch{patch_size[0]}x{patch_size[1]}_{step_size}/{split}/instance_labels/{name}.tif', f'{save_root}/instance_labels/{name}.tif')\n",
    "        shutil.copy(f'{save_root}/allpatch{patch_size[0]}x{patch_size[1]}_{step_size}/{split}/semantic_labels/{name}.png', f'{save_root}/semantic_labels/{name}.png')\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09f0d74-2b8e-4218-9898-2450c8c569a0",
   "metadata": {},
   "source": [
    "# 1. Train\n",
    "**!!! Attention**: The checkpoints will be saved every 10000 steps. This will consume a lot of storage space (hundreds of GB). You can type `df -h` to monitor the storage and can delete some early checkpoints (e.g checkpoints <100000 steps) to free storage space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eaad3f-f285-4f1a-8f68-7ac0c1ebaac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = 'monuseg/allpatch256x256_128' # directory saving training subsets of different labeling proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c93d0e-58f5-44c9-b2ef-746e460b7d54",
   "metadata": {},
   "source": [
    "## 1.1 Nuclei structure synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e05fc-f523-47a5-93ff-554395486eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "prop = 0.11\n",
    "max_iterations = 200000\n",
    "bs = 4\n",
    "logdir = f'logs/monuseg_mask/prop{prop:.1f}' # logging directory\n",
    "datadir = f'{data_root}/train_6class_prop{prop:.2f}' if prop < 1 else f'{data_root}/train'\n",
    "assert os.path.exists(datadir)\n",
    "print(os.path.exists(logdir))\n",
    "command = f'CUDA_VISIBLE_DEVICES={gpu_id} OPENAI_LOGDIR={logdir} \\\n",
    "            python scripts/struct_syn/struct_train.py \\\n",
    "            --data_dir {datadir} \\\n",
    "            --attention_resolutions 32,16,8 --class_cond False --diffusion_steps 1000 --image_size 256 \\\n",
    "            --learn_sigma True --noise_schedule linear --num_channels 256 --num_head_channels 64 --num_res_blocks 2 \\\n",
    "            --resblock_updown True --use_fp16 True --use_scale_shift_norm True \\\n",
    "            --max_iterations {max_iterations} --batch_size {bs} --lr 1e-4 --weight_decay 0.05 \\\n",
    "            --save_interval 10000 --viz_interval 10000 --viz_batch_size 4'\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60684b86-f91f-4e9e-a505-a57954e274d7",
   "metadata": {},
   "source": [
    "## 1.2 Nuclei image synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c1e83-6ceb-4f1c-82b6-62c7b0ed9275",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pretrain\n",
    "prop = 0.11\n",
    "gpu_id = 0\n",
    "max_iterations = '150000'\n",
    "bs = 1\n",
    "logdir = f'logs/monuseg/prop{prop:.1f}_pretrain' # logging directory\n",
    "datadir = f'{data_root}/train_6class_prop{prop:.2f}' if prop < 1 else f'{data_root}/train'\n",
    "viz_datadir = f'{data_root}/test'\n",
    "assert os.path.exists(datadir)\n",
    "assert os.path.exists(viz_datadir)\n",
    "print(os.path.exists(logdir))\n",
    "command = f'CUDA_VISIBLE_DEVICES={gpu_id} OPENAI_LOGDIR={logdir} \\\n",
    "            python scripts/image_syn/train.py \\\n",
    "            --data_dir {datadir} \\\n",
    "            --viz_data_dir {viz_datadir} \\\n",
    "            --lr 1e-4 --batch_size {bs} --attention_resolutions 32,16,8 --diffusion_steps 1000 --image_size 256 --learn_sigma True \\\n",
    "            --noise_schedule linear --num_channels 256 --num_head_channels 64 --num_res_blocks 2 --resblock_updown True --use_fp16 True \\\n",
    "            --use_scale_shift_norm True --use_checkpoint False --num_classes 2 --class_cond True --no_instance False \\\n",
    "            --max_iterations {max_iterations} --save_interval 10000 --viz_interval 10000 --viz_batch_size 4'\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84736fd4-ee93-48fa-b4b5-954a86c9bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finetune: classifier-free training (continue on the basis of the last checkpoint of the pretrain step)\n",
    "prop = 0.11\n",
    "gpu_id = 0\n",
    "max_iterations = 300000\n",
    "bs = 1\n",
    "step = '150000' # set this to be max_iterations of the pretrain step\n",
    "logdir = f'logs/monuseg/prop{prop:.1f}_finetune' # logging directory\n",
    "datadir = f'{data_root}/train_6class_prop{prop:.2f}' if prop < 1 else f'{data_root}/train'\n",
    "viz_datadir = f'{data_root}/test' # visualization directory\n",
    "preckpt = f'logs/monuseg/prop{prop:.1f}_pretrain/model{step}.pt'\n",
    "assert os.path.exists(datadir)\n",
    "assert os.path.exists(viz_datadir)\n",
    "assert os.path.exists(preckpt)\n",
    "print(os.path.exists(logdir))\n",
    "command = f'CUDA_VISIBLE_DEVICES={gpu_id} OPENAI_LOGDIR={logdir} \\\n",
    "            python scripts/image_syn/train.py \\\n",
    "            --data_dir {datadir} \\\n",
    "            --viz_data_dir {viz_datadir} \\\n",
    "            --resume_checkpoint {preckpt} \\\n",
    "            --unet unet \\\n",
    "            --lr 2e-5 --batch_size {bs} --attention_resolutions 32,16,8 --diffusion_steps 1000 --image_size 256 --learn_sigma True \\\n",
    "            --noise_schedule linear --num_channels 256 --num_head_channels 64 --num_res_blocks 2 --resblock_updown True --use_fp16 True \\\n",
    "            --use_scale_shift_norm True --use_checkpoint False --num_classes 2 --class_cond True --no_instance False --drop_rate 0.2 \\\n",
    "            --max_iterations {max_iterations} --save_interval 10000 --viz_interval 10000 --viz_batch_size 4'\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be60068-e756-4bfb-a82a-c69fad16daf4",
   "metadata": {},
   "source": [
    "# 2. Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af17e9-562f-40b1-bb3d-bc267d2db95b",
   "metadata": {},
   "source": [
    "## 2.1 Nuclei structure synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdeda34-4564-4ea3-8dd3-57ddf5a9edd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "step1 = '150000' # select one checkpoint in step1\n",
    "prop = 0.1\n",
    "bs = 32\n",
    "num_samples = 512\n",
    "modelpath = f'logs/monuseg_mask/prop{prop:.1f}/model{step1}.pt'\n",
    "resdir = f'results/monuseg_mask/prop{prop:.1f}/{step1}_{num_samples}'\n",
    "assert os.path.exists(modelpath)\n",
    "print(os.path.exists(resdir))\n",
    "command = f'CUDA_VISIBLE_DEVICES={gpu_id} OPENAI_LOGDIR={resdir} \\\n",
    "            python scripts/struct_syn/struct_sample.py \\\n",
    "            --model_path {modelpath} --results_path {resdir} \\\n",
    "            --attention_resolutions 32,16,8 --class_cond False --diffusion_steps 1000 --image_size 256 --in_channels 3 \\\n",
    "            --learn_sigma True --noise_schedule linear --num_channels 256 --num_head_channels 64 --num_res_blocks 2 \\\n",
    "            --resblock_updown True --use_fp16 True --use_scale_shift_norm True \\\n",
    "            --batch_size {bs} --num_samples {num_samples}'\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb5cec-5844-40be-a216-075843322a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get instance map from nuclei structures\n",
    "prop = 0.11\n",
    "datadir = f'results/monuseg_mask/prop{prop:.1f}/{step1}_{num_samples}'\n",
    "inst_path = f'{datadir}/instances'\n",
    "os.makedirs(inst_path, exist_ok=True)\n",
    "files = sorted(glob.glob(f'{datadir}/samples/*.png'))\n",
    "names = [x.split('/')[-1].split('.')[0] for x in files]\n",
    "print(len(names))\n",
    "masks = [io.imread(x) for x in files]\n",
    "labels = []\n",
    "for mask in tqdm(masks):\n",
    "    label = get_instance_map(mask)\n",
    "    labels.append(label)\n",
    "for name, label in zip(names, labels):\n",
    "    sio.savemat(f'{inst_path}/{name}.mat', {'inst_map': label})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ff6fe5-5aaa-4005-a196-5f4e46cfc32f",
   "metadata": {},
   "source": [
    "## 2.2 Nuclei image synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a427ec9-9fcc-4257-a893-8c6e58e53d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_id = 0\n",
    "prop = 0.11\n",
    "step2 = '150000' # select the checkpoint in step2\n",
    "s = 2.0\n",
    "num_samples = 512\n",
    "modelpath = f'logs/monuseg/prop{prop:.1f}_finetune/model{step2}.pt'\n",
    "datadir = f'results/monuseg_mask/prop{prop:.1f}/{step1}_{num_samples}/samples'\n",
    "resdir = f'results/monuseg_mask/prop{prop:.1f}/{step1}_{num_samples}/finetune_{step2}_s{s}'\n",
    "assert os.path.exists(modelpath)\n",
    "assert os.path.exists(datadir)\n",
    "print(os.path.exists(resdir))\n",
    "command = f'CUDA_VISIBLE_DEVICES={gpu_id} OPENAI_LOGDIR={resdir} \\\n",
    "            python scripts/image_syn/sample.py \\\n",
    "            --data_dir {datadir} --model_path {modelpath} --results_path {resdir} --input_mask True \\\n",
    "            --attention_resolutions 32,16,8 --diffusion_steps 1000 --image_size 256 --learn_sigma True \\\n",
    "            --noise_schedule linear --num_channels 256 --num_head_channels 64 --num_res_blocks 2 --resblock_updown True --use_fp16 True \\\n",
    "            --use_scale_shift_norm True --num_classes 2 \\\n",
    "            --class_cond True --no_instance False --batch_size 28 --num_samples {num_samples} --s {s} --seed 0'\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820d9f7b-eb0d-4277-9e99-221f7ba6c419",
   "metadata": {},
   "source": [
    "# 3. Hover-net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f2716c-f43f-4305-b60f-26c99f84e0d1",
   "metadata": {},
   "source": [
    "## 3.1 Extract patches\n",
    "Run the following commands under current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd26e2cc-bcd6-4fa8-aa9c-4b7d5cd065be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## you need to set paths in scripts/hovernet/extract_patches.py\n",
    "command = 'python scripts/hovernet/extract_patches.py'\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fec2da-4dd7-4a34-bedf-de1bcdad9178",
   "metadata": {},
   "source": [
    "## 3.2 Train\n",
    "Run the following commands under current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880a19e5-151b-4a65-a29d-a7fd5116b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## you need to set paths in scripts/hovernet/hovernet_config.py\n",
    "command = 'python scripts/hovernet/train.py --gpu=0'\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebab8bc-db7f-4660-951d-b77dbc772060",
   "metadata": {},
   "source": [
    "## 3.3 Test\n",
    "Run the following commands under the `hover_net` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4452ac-aa6d-472c-8f04-fd5e7347ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict\n",
    "prop = 0.11\n",
    "epoch = 10 # select one checkpoint of hovernet according to validation metrics\n",
    "# for 10%/20%/50%/100% labeled\n",
    "dirname = f'monuseg_prop{prop:.1f}' \n",
    "# # for 10%/20%/50%/100% augmented\n",
    "# num_samples = 512 # for example\n",
    "# dirname = f'monuseg_prop{prop:.1f}+_syn_{num_samples}' \n",
    "segckpt = f'hovernet_logs/{dirname}/256x256_164x164/01/net_epoch={epoch}.tar'\n",
    "assert os.path.exists(segckpt)\n",
    "command = f'python run_infer.py \\\n",
    "            --gpu=0 \\\n",
    "            --model_path={segckpt} \\\n",
    "            --model_mode=fast --batch_size=64 \\\n",
    "            tile \\\n",
    "            --input_dir=/data/yuxinyi/MoNuSeg/test/images \\\n",
    "            --output_dir=hovernet_results/{dirname}/256x256_164x164'\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071539df-c8e8-4500-9e9a-fdca1e003446",
   "metadata": {},
   "outputs": [],
   "source": [
    "## stats\n",
    "command = f'python compute_stats.py \\\n",
    "            --mode instance \\\n",
    "            --true_dir /data/yuxinyi/MoNuSeg/test/labels \\\n",
    "            --pred_dir hovernet_results/{dirname}/256x256_164x164/mat'\n",
    "print(command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "histo",
   "language": "python",
   "name": "histo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
